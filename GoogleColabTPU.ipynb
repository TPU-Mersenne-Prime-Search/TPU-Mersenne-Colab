{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<h4>(1 - Recommend). Create and save new notebook(s) to enable automatic re-mounting of Drive storage. Copy and paste the below code into a <a href=\"http://colab.research.google.com/#create=true\" target=\"_parent\">new notebook</a> in Colab and follow the directions in the <a href=\"https://github.com/TPU-Mersenne-Prime-Search/TensorPrime/wiki/Usage-and-Arguments\" target=\"_parent\">Wiki</a></h4><h4>(2). Open the pre-formed version in Colab (requires manual authorization each time a notebook is opened) <a href=\"https://colab.research.google.com/github/TPU-Mersenne-Prime-Search/TensorPrime/blob/master/GoogleColabTPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
     "#@title # **üìî Colab TPU Notebook**#{ vertical-output: true, display-mode: \"form\" }\n",
     "\n",
     "import os\n",
     "\n",
     "#@markdown #### ‚ÜñÔ∏è Click the ‚ñ∂Ô∏è button after deciding on the options below.\n",
     "#@markdown #### üîå Make sure the TPU is enabled under *Runtime‚ÜíChange runtime type*\n",
     "#@markdown #### üí° Keep each notebook **open** in the browser to prevent disconnection. üìå [the tab](https://support.mozilla.org/kb/pinned-tabs-keep-favorite-websites-open) or move them to a dedicated window for easy access.\n",
     "#@markdown #### ‚ÑπÔ∏è This notebook uses our [TensorPrime](https://github.com/TPU-Mersenne-Prime-Search/TensorPrime) program and [PrimeNet Python script](https://github.com/tdulcet/Distributed-Computing-Scripts#primenet).\n",
     "#@markdown #### üìú Please see the [Wiki](https://github.com/TPU-Mersenne-Prime-Search/TensorPrime/wiki) for more information.\n",
     "#@markdown #### ü§∑ Optionally, create a GIMPS/PrimeNet account [here](https://www.mersenne.org/update/) and [join](https://www.mersenne.org/jteam/) the ‚ÄúPortland State University‚Äù team!\n",
     "\n",
     "# TODO: Remove these inputs once TensorPrime is able to support wavefront exponents\n",
     "exponent = 4423 #@param {type:\"integer\"}\n",
     "fft_length = 0 #@param {type:\"integer\"}\n",
     "#@markdown üìè If no FFT/signal length is specified, TensorPrime will automatically compute the signal length as $2^{floor(log_2(exponent/2.5))}$.\n",
     "# prime_ID = 'Default' #@param ['Default'] {allow-input: true}\n",
     "# computer_name = 'Default' #@param ['Default'] {allow-input: true}\n",
     "# TODO: Remove any worktypes the TPU program does not end up supporting from the below list\n",
     "# type_of_work = '150 - First time PRP tests' #@param ['4 - P-1 factoring', '100 - First time LL tests', '101 - Double-check LL tests', '102 - World record LL tests', '104 - 100 million digit LL tests', '150 - First time PRP tests', '151 - Double-check PRP tests', '152 - World record PRP tests', '153 - 100 million digit PRP tests', '154 - First time PRP tests that need P-1 factoring', '155 - Double-check tests using PRP with proof', '160 - First time PRP on Mersenne cofactors', '161 - Double-check PRP on Mersenne cofactors']\n",
     "# prp_proof_power = '5' #@param ['4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
     "# #@markdown Every lower power halves Drive storage requirements for PRP tests, but doubles the certification cost. Drive storage (GiB) needed for PRP tests:\n",
     "# \n",
     "# #@markdown Proof<br>Power | Exponent 50M | Exponent 100M | Exponent 150M | Exponent 200M | Exponent 250M | Exponent 300M | Exponent 332.1M<br>(100M digits)\n",
     "# #@markdown --- | ---: | ---: | ---: | ---: | ---: | ---: | ---:\n",
     "# #@markdown 5 | 0.186 | 0.372 | 0.558 | 0.745 | 0.931 | 1.117 | 1.237\n",
     "# #@markdown 6 | 0.372 | 0.745 | 1.117 | 1.49 | 1.862 | 2.235 | 2.475\n",
     "# #@markdown 7 | 0.745 | 1.49 | 2.235 | **2.98** | **3.725** | **4.47** | **4.95**\n",
     "# #@markdown 8 | 1.49 | **2.98** | **4.47** | 5.96 | 7.45 | 8.94 | 9.9\n",
     "# #@markdown 9 | ***2.98*** | *5.96* | 8.94 | 11.9 | 14.9 | 17.88 | 19.8\n",
     "# #@markdown 10 | 5.96 | 11.92 | *17.88* | *23.84* | *29.8* | *35.76* | *39.6*\n",
     "# #@markdown 11 | 11.92 | 23.84 | 35.76 | 47.68 | 59.6 | 71.52 | 79.2\n",
     "# #@markdown 12 | 23.84 | 47.68 | 71.52 | 95.36 | 119.2 | 143 | 158.4\n",
     "# proof_certification_work = True #@param {type:\"boolean\"}\n",
     "computer_number = 'Default (1)' #@param ['Default (1)', '2', '3', '4'] {allow-input: true}\n",
     "local_time = 'Pacific' #@param ['Pacific', 'Mountain', 'Central', 'Eastern', 'Alaska', 'Hawaii']\n",
     "debug = 'False' #@param ['False', 'TPU (TensorPrime)']\n",
     "\n",
     "#@markdown #### üêõ The *debug* option outputs TPU (TensorPrime) progress and status, then exits.\n",
     "\n",
     "# TODO: replace TODO below with command to determine current TPU\n",
     "tpu_info = ['TODO'] # Output what TPU is assigned to this Notebook\n",
     "\n",
     "\n",
     "class StopExecution(Exception):\n",
     "  def _render_traceback_(self):\n",
     "      pass\n",
     "\n",
     "def run():\n",
     "  '''Run TensorPrime.'''\n",
     "  # print('\\nStarting PrimeNet\\n')\n",
     "  # !cd tensorprime; nohup python3 -OO ../primenet.py --checkin 1 -T {type_of_work} -l '{'local' + computer_number + '.ini'}' >> '{'primenet' + computer_number + '.out'}' &\n",
     "  # !sleep 1\n",
     "  # while not os.path.exists(f'tensorprime/worktodo{computer_number}.txt'):\n",
     "    # print(f'Waiting for worktodo{computer_number}.txt access...')\n",
     "    # !sleep 1\n",
     "\n",
     "  os.chmod('tensorprime/main.py', 0o777)\n",
     "  print('\\nStarting TensorPrime\\n')\n",
     "  # TODO: Remove this and add assignment handling to TensorPrime\n",
     "  global exponent\n",
     "  if not exponent:\n",
     "    with open(f'tensorprime/worktodo{computer_number}.txt') as file:\n",
     "      for line in file:\n",
     "        work_type = line.split('=', 1)[0]\n",
     "        if work_type in {'PRP', 'PRPDC'}:\n",
     "          found = line.split(',')\n",
     "          exponent = int(found[3])\n",
     "          print(f'Exponent: {exponent}')\n",
     "          !cd tensorprime && time python3 -OO main.py -p {exponent} | tee -ia '{'tpu' + computer_number + '.out'}'\n",
     "  else:\n",
     "    !cd tensorprime && time python3 -OO main.py -p {exponent} --fft {fft_length} | tee -ia '{'tpu' + computer_number + '.out'}'\n",
     "\n",
     "def install():\n",
     "  '''Download/Install/Configure TensorPrime.'''\n",
     "  print('Downloading, building and setting up TensorPrime\\n')\n",
     "  !wget -O master.zip https://github.com/TPU-Mersenne-Prime-Search/TensorPrime/archive/master.zip\n",
     "  !unzip -o master.zip\n",
     "  !mv TensorPrime-master/ tensorprime\n",
     "  !wget -nv -O tensorprime/primenet.py https://raw.github.com/tdulcet/Distributed-Computing-Scripts/master/primenet.py\n",
     "  # print(\"Registering computer with PrimeNet\\n\")\n",
     "  # TODO: This --tpu option would need to be added unless you integrate PrimeNet support into TensorPrime\n",
     "  # !cd tensorprime && python3 primenet.py -OO -t 0 -W 1 -T {type_of_work} -u '{prime_ID}' -i '{'worktodo' + computer_number + '.txt'}' -r '{'results' + computer_number + '.txt'}' -l '{'local' + computer_number + '.ini'}' --tpu -H '{computer_name}'\n",
     "  run()\n",
     "\n",
     "def debug_exit():\n",
     "  '''Output TPU and output of Prime95 or TensorPrime output.'''\n",
     "  if debug == 'TPU (TensorPrime)' and os.path.exists(f'tensorprime/tpu{computer_number}.out'):\n",
     "    print(f'\\nOutput for computer number {computer_number}:\\n')\n",
     "    print('\\nPrimeNet output:\\n')\n",
     "    # !tail -n 100 '{'tensorprime/primenet' + computer_number + '.out'}' # view primenet output\n",
     "    print('\\nTPU (TensorPrime) output: ')\n",
     "    !tail -n 100 '{'tensorprime/tpu' + computer_number + '.out'}' # view TensorPrime progress\n",
     "    # !cd tensorprime && python3 -OO primenet.py -l '{'local' + computer_number + '.ini'}' -s\n",
     "    print()\n",
     "  else:\n",
     "    print(f'No `{debug!r}` output file found for debug option and computer number `{computer_number!r}`.\\n')\n",
     "\n",
     "def load_drive():\n",
     "  '''Load & cd into gdrive for persistent data.'''\n",
     "  if os.path.exists('/content/drive/My Drive'): # create your own notebook with our code\n",
     "    %cd \"/content/drive/My Drive\"\n",
     "  else: # use our notebook\n",
     "    print('Warning: Google Drive is not mounted')\n",
     "    print('If you were not expecting this, on the far left click the folder icon, the \"Mount Drive\" folder button, select \"CONNECT TO GOOGLE DRIVE\" ')\n",
     "    print('and then re-execute this cell.')\n",
     "    from google.colab import drive\n",
     "    drive.mount('/content/gdrive')\n",
     "    %cd \"/content/gdrive/My Drive\"\n",
     "  if 'My Drive/GIMPS' in os.getcwd(): # don't create a subfolder in GIMPS/\n",
     "    return\n",
     "  os.makedirs('GIMPS', exist_ok=True)\n",
     "  %cd \"GIMPS\"\n",
     "\n",
     "def tpu_check():\n",
     "  '''TPU Check.'''\n",
     "  global tpu_info\n",
     "  tpu_info = '\\n'.join(tpu_info)\n",
     "  # TOOD -- this will likely have to change\n",
     "  if tpu_info.find('failed') >= 0:\n",
     "    print('Select the \"Runtime\" ‚Üí \"Change runtime type\" ‚Üí \"TPU\" ‚Üí \"SAVE\" to enable a TPU accelerator, ')\n",
     "    print('and then re-execute this cell.')\n",
     "    raise StopExecution\n",
     "  print(f'\\nTensor Processor (TPU):\\t{tpu_info}\\n')\n",
     "\n",
     "tpu_check()\n",
     "!wget https://raw.github.com/tdulcet/Linux-System-Information/master/info.sh -qO - | bash -s # Check System Info\n",
     "!python3 -V\n",
     "print()\n",
     "load_drive()\n",
     "\n",
     "# set local time\n",
     "!rm -f /etc/localtime\n",
     "!ln -s {'/usr/share/zoneinfo/US/' + local_time} /etc/localtime\n",
     "\n",
     "# use/cleanup input from user\n",
     "# prime_ID = 'psu' if prime_ID.lower() == 'default' else prime_ID\n",
     "# computer_name = \"\" if computer_name.lower() == 'default' else computer_name\n",
     "computer_number = '1' if computer_number.lower() == 'default (1)' else computer_number.strip()\n",
     "# type_of_work = type_of_work.split(\"-\", 1)[0].rstrip()\n",
     "# proof_certification_work = \"y\" if proof_certification_work else \"n\"\n",
     "debug = False if debug == 'False' else debug\n",
     "\n",
     "if debug:\n",
     "  debug_exit()\n",
     "  raise StopExecution\n",
     "\n",
     "elif not computer_number.isdigit() or int(computer_number) < 0:\n",
     "  print('ERROR: Computer number must be a number')\n",
     "  raise StopExecution\n",
     "\n",
     "# elif os.path.exists(f'tensorprime/local{computer_number}.ini'):\n",
     "elif os.path.exists('tensorprime'):\n",
     "  !cd tensorprime && echo -e \"$(date)\\t$(sed -n 's/^model name[[:space:]]*: *//p' /proc/cpuinfo | uniq)  $(sed -n 's/^model[[:space:]]*: *//p' /proc/cpuinfo | uniq)\" >> cpus.txt\n",
     "  print('\\nPrevious CPU counts')\n",
     "  !cd tensorprime; cut -f 2 cpus.txt | sort | uniq -c | sort -nr\n",
     "  # !cd tensorprime && echo -e \"$(date)\\t$tpu_info\" >> tpus.txt\n",
     "  print('\\nPrevious TPU counts')\n",
     "  # !cd tensorprime; cut -f 2 tpus.txt | sort | uniq -c | sort -nr\n",
     "  run()\n",
     "\n",
     "else:\n",
     "  install()\n",
     "\n",
     "print('Gracefully exiting...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
